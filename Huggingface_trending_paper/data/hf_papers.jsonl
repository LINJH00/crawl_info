{"url": "https://huggingface.co/papers/2509.13310", "title": "Scaling Agents via Continual Pre-training", "context": "AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.\nLarge language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving.\nHowever, post-training approaches building upon general-purpose foundation\nmodels consistently underperform in agentic tasks, particularly in open-source\nimplementations. We identify the root cause: the absence of robust agentic\nfoundation models forces models during post-training to simultaneously learn\ndiverse agentic behaviors while aligning them to expert demonstrations, thereby\ncreating fundamental optimization tensions. To this end, we are the first to\npropose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational\nmodels. Based on this approach, we develop a deep research agent model named AgentFounder . We evaluate our AgentFounder -30B on 10 benchmarks and achieve\nstate-of-the-art performance while retains strong tool-use ability, notably\n39.9% on BrowseComp-en , 43.3% on BrowseComp-zh , and 31.5% Pass@1 on HLE ."}
{"url": "https://huggingface.co/papers/2509.13313", "title": "ReSum: Unlocking Long-Horizon Search Intelligence via Context\n  Summarization", "context": "ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.\nLarge Language Model ( LLM )-based web agents demonstrate strong performance on knowledge-intensive tasks but are hindered by context window limitations in\nparadigms like ReAct . Complex queries involving multiple entities, intertwined\nrelationships, and high uncertainty demand extensive search cycles that rapidly\nexhaust context budgets before reaching complete solutions. To overcome this\nchallenge, we introduce ReSum , a novel paradigm that enables indefinite\nexploration through periodic context summarization . ReSum converts growing\ninteraction histories into compact reasoning states , maintaining awareness of\nprior discoveries while bypassing context constraints. For paradigm adaptation,\nwe propose ReSum-GRPO , integrating GRPO with segmented trajectory training and advantage broadcasting to familiarize agents with summary-conditioned\nreasoning. Extensive experiments on web agents of varying scales across three\nbenchmarks demonstrate that ReSum delivers an average absolute improvement of\n4.5\\% over ReAct , with further gains of up to 8.2\\% following ReSum-GRPO training. Notably, with only 1K training samples, our WebResummer-30B (a ReSum-GRPO -trained version of WebSailor-30B ) achieves 33.3\\% Pass@1 on BrowseComp-zh and 18.3\\% on BrowseComp-en , surpassing existing open-source web\nagents."}
{"url": "https://huggingface.co/papers/2509.13305", "title": "WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic\n  Data and Scalable Reinforcement Learning", "context": "WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.\nTranscending human cognitive limitations represents a critical frontier in LLM training . Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex information-seeking benchmarks\nsuch as BrowseComp , a feat previously unattainable. We posit that their success\nhinges on a sophisticated reasoning pattern absent in open-source models: the\nability to systematically reduce extreme uncertainty when navigating vast\ninformation landscapes. Based on this insight, we introduce WebSailor, a\ncomplete post-training methodology designed to instill this crucial capability.\nOur approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation , RFT cold start , and an\nefficient agentic RL training algorithm, Duplicating Sampling Policy\nOptimization ( DUPO ). With this integrated pipeline, WebSailor significantly\noutperforms all open-source agents in complex information-seeking tasks,\nmatching proprietary agents' performance and closing the capability gap."}
{"url": "https://huggingface.co/papers/2509.13312", "title": "WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for\n  Open-Ended Deep Research", "context": "WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.\nThis paper tackles open-ended deep research (OEDR), a complex challenge where AI agents must synthesize vast web-scale information into insightful reports.\nCurrent approaches are plagued by dual-fold limitations: static research\npipelines that decouple planning from evidence acquisition and one-shot\ngeneration paradigms that easily suffer from long-context failure issues like\n\" loss in the middle \" and hallucinations . To address these challenges, we\nintroduce WebWeaver, a novel dual-agent framework that emulates the human\nresearch process. The planner operates in a dynamic cycle, iteratively\ninterleaving evidence acquisition with outline optimization to produce a\ncomprehensive, source-grounded outline linking to a memory bank of evidence.\nThe writer then executes a hierarchical retrieval and writing process ,\ncomposing the report section by section. By performing targeted retrieval of\nonly the necessary evidence from the memory bank for each part, it effectively\nmitigates long-context issues. Our framework establishes a new state-of-the-art\nacross major OEDR benchmarks, including DeepResearch Bench , DeepConsult , and DeepResearchGym . These results validate our human-centric, iterative\nmethodology, demonstrating that adaptive planning and focused synthesis are\ncrucial for producing high-quality, reliable, and well-structured reports."}
{"url": "https://huggingface.co/papers/2507.02592", "title": "WebSailor: Navigating Super-human Reasoning for Web Agent", "context": "WebSailor, a post-training methodology, enhances open-source LLMs with sophisticated reasoning to match proprietary systems in complex information-seeking tasks.\nTranscending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex information-seeking benchmarks\nsuch as BrowseComp , a feat previously unattainable. We posit that their success\nhinges on a sophisticated reasoning pattern absent in open-source models: the\nability to systematically reduce extreme uncertainty when navigating vast\ninformation landscapes. Based on this insight, we introduce WebSailor, a\ncomplete post-training methodology designed to instill this crucial capability.\nOur approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation , RFT cold start , and an\nefficient agentic RL training algorithm, Duplicating Sampling Policy\nOptimization ( DUPO ). With this integrated pipeline, WebSailor significantly\noutperforms all opensource agents in complex information-seeking tasks,\nmatching proprietary agents' performance and closing the capability gap."}
