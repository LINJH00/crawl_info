{"url": "https://techcrunch.com/2025/09/18/openais-research-on-ai-models-deliberately-lying-is-wild/", "title": "OpenAI’s research on AI models deliberately lying is wild", "date": "2025-09-18", "content": "Every now and then, researchers at the biggest tech companies drop a bombshell. There was the time Google said its latest quantum chip indicated multiple universes exist. Or when Anthropic gave its AI agent Claudius a snack vending machine to run and it went amok, calling security on people and insisting it was human.\nThis week, it was OpenAI’s turn to raise our collective eyebrows.\nOpenAI released on Monday some research that explained how it’s stopping AI models from “scheming.” It’s a  practice in which an “AI behaves one way on the surface while hiding its true goals,” OpenAI defined in its tweet about the research.\nIn the paper, conducted with Apollo Research, researchers went a bit further, likening AI scheming to a human stock broker breaking the law to make as much money as possible. The researchers, however, argued that most AI “scheming” wasn’t that harmful. “The most common failures involve simple forms of deception — for instance, pretending to have completed a task without actually doing so,” they wrote.\nThe paper was mostly published to show that “deliberative alignment⁠” — the anti-scheming technique they were testing — worked well.\nBut it also explained that AI developers haven’t figured out a way to train their models not to scheme. That’s because such training could actually teach the model how to scheme even better to avoid being detected.\n“A major failure mode of attempting to ‘train out’ scheming is simply teaching the model to scheme more carefully and covertly,” the researchers wrote.\nPerhaps the most astonishing part is that, if a model understands that it’s being tested, it can pretend it’s not scheming just to pass the test, even if it is still scheming. “Models often become more aware that they are being evaluated. This situational awareness can itself reduce scheming, independent of genuine alignment,” the researchers wrote.\nIt’s not news that AI models will lie. By now most of us have experienced AI hallucinations, or the model confidently giving an answer to a prompt that simply isn’t true. But hallucinations are basically presenting guesswork with confidence, as OpenAI research released earlier this month documented.\nScheming is something else. It’s deliberate.\nEven this revelation — that a model will deliberately mislead humans — isn’t new. Apollo Research first published a paper in December documenting how five models schemed when they were given instructions to achieve a goal “at all costs.”\nThe news here is actually good news: The researchers saw significant reductions in scheming by using “deliberative alignment⁠.” That technique involves teaching the model an “anti-scheming specification” and then making the model go review it before acting. It’s a bit like making little kids repeat the rules before allowing them to play.\nOpenAI researchers insist that the lying they’ve caught with their own models, or even with ChatGPT, isn’t that serious. As OpenAI’s co-founder Wojciech Zaremba told TechCrunch’s Maxwell Zeff about this research: “This work has been done in the simulated environments, and we think it represents future use cases. However, today, we haven’t seen this kind of consequential scheming in our production traffic. Nonetheless, it is well known that there are forms of deception in ChatGPT. You might ask it to implement some website, and it might tell you, ‘Yes, I did a great job.’ And that’s just the lie. There are some petty forms of deception that we still need to address.”\nThe fact that AI models from multiple players intentionally deceive humans is, perhaps, understandable. They were built by humans, to mimic humans, and (synthetic data aside) for the most part trained on data produced by humans.\nIt’s also bonkers.\nWhile we’ve all experienced the frustration of poorly performing technology (thinking of you, home printers of yesteryear), when was the last time your not-AI software deliberately lied to you? Has your inbox ever fabricated emails on its own? Has your CMS logged new prospects that didn’t exist to pad its numbers? Has your fintech app made up its own bank transactions?\nIt’s worth pondering this as the corporate world barrels toward an AI future where companies believe agents can be treated like independent employees. The researchers of this paper have the same warning.\n“As AIs are assigned more complex tasks with real-world consequences and begin pursuing more ambiguous, long-term goals, we expect that the potential for harmful scheming will grow — so our safeguards and our ability to rigorously test must grow correspondingly,” they wrote."}
{"url": "https://techcrunch.com/2025/09/18/huawei-announces-new-ai-infrastructure-as-nvidia-gets-locked-out-of-china/", "title": "Huawei announces new AI infrastructure as Nvidia gets locked out of China", "date": "2025-09-18", "content": "Tech giant Huawei unveiled new AI infrastructure meant to help boost compute power and allow the company to better compete with rival chipmaker Nvidia.\nAt a keynote at its Huawei Connect conference on Thursday, Shenzhen, China-based Huawei announced new SuperPoD Interconnect technology that can link together up to 15,000 graphics cards, including Huawei’s Ascend AI chips, to increase compute power.\nThis tech seems to be a competitor for Nvidia’s NVLink infrastructure, which facilitates high-speed communication between AI chips.\nTechnology like this is critical for Huawei to better compete with semiconductors like Nvidia’s. While Huawei’s AI chips are less powerful than Nvidia’s, being able to cluster them together will give its users access to more compute power, which is needed for training and scaling AI systems.\nThis news also comes just a day after China banned domestic tech companies from buying Nvidia’s hardware, including Nvidia’s RTX Pro 600D servers specifically designed for the market in China.\nTechCrunch reached out to Huawei for more information."}
{"url": "https://techcrunch.com/2025/09/18/how-ai-startups-are-fueling-googles-booming-cloud-business/", "title": "How AI startups are fueling Google’s booming cloud business", "date": "2025-09-18", "content": "Google Cloud announced Thursday it has added fast-rising AI coding startups Lovable and Windsurf to its roster of customers. Both companies have chosen Google Cloud as their primary cloud computing provider, the latest sign of Google’s rising prominence against larger rivals AWS and Microsoft Azure.\nThe deals also highlight Google’s efforts to make its cloud business more central to the company’s future.\nToday, Google Cloud is overshadowed by larger competitors like AWS and Microsoft, as well as Google’s much larger advertising business. But it is seeing upward momentum.\nGoogle Cloud is one of the company’s fastest-growing business lines. On its last earnings call, Google said its cloud division hit an annual run rate of $50 billion, and cloud chief Thomas Kurian said this week the unit lined up $58 billion in new revenue over the next two years. Google generated $43.2 billion in cloud services in 2024 and $33.1 billion in 2023.\nWinning contracts with leading AI startups seems to be a large driver of Google Cloud’s growth. The division says it now works with nine out of the 10 leading AI labs, including Safe Superintelligence and OpenAI , and 60% of the world’s generative AI startups. In the last year, the company says it’s seen a 20% increase in the number of new AI startups choosing Google Cloud.\nWhile Lovable and Windsurf, which was recently acquired by Cognition , spend relatively little compared to leading AI labs or large enterprises, the bet is that they will become larger businesses in the future, and well worth the investment.\nGoogle says the two vibe-coding startups use Gemini 2.5 Pro to power their products, which are also run on Google Cloud infrastructure. Google says Windsurf is also using Gemini models in integrations with Cognition’s AI agent, Devin.\nThe significant cloud costs of training, fine-tuning, and running AI models has presented a major challenge for AI model developers, including Google DeepMind with its Gemini models. But it’s been a boon for cloud businesses. The global cloud market is expected to exceed $400 billion in 2025 and grow at a rate of 20% over the next five years, according to the market intelligence and analytics firm Synergy Research.\nThe company on Thursday hosted its first Google AI Builder’s Forum, in which it brought together hundreds of AI startup founders and announced more than 40 new AI startups building on Google Cloud. In addition to Lovable and Windsurf, Sequoia-backed Factory AI and Andreessen Horowitz-backed Krea AI were among the customers named.\nPart of the reason so many AI startups work with Google Cloud are the generous deals it offers. Many of the AI startups Google works with started on its Google for Startups Cloud Program, in which it offers $350,000 in cloud credits. Google Cloud also offers a dedicated cluster of Nvidia GPUs for startups in the Y Combinator accelerator program."}
{"url": "https://techcrunch.com/2025/09/18/tim-cook-sam-altman-and-more-attend-trumps-uk-state-banquet/", "title": "Tim Cook, Sam Altman, and more attend Trump’s UK state banquet", "date": "2025-09-18", "content": "Top tech names were on the guest list for the banquet thrown for President Trump during his second state visit to the U.K. on Wednesday.\nThe banquet seating chart included Nvidia CEO Jensen Huang; Apple CEO Tim Cook; venture capitalist and White House AI and crypto czar David Sacks; Alphabet and Google president Ruth Porat; Microsoft CEO Satya Nadella; Salesforce CEO Marc Benioff; and OpenAI’s Sam Altman, according to the New York Times .\nOn Thursday, the U.S. and U.K. signed a partnership called the Tech Prosperity Deal to focus on developing nuclear, AI, and quantum technologies. Google, Microsoft, Nvidia, and OpenAI also made announcements earlier this week to build data centers in the U.K., while CoreWeave and Salesforce announced a multibillion-pound investment in the country. Overall, American tech firms committed a total of £31 billion ($42 billion) to boost AI infrastructure in the U.K.\nThis state banquet guest list seems to have featured more tech and business names than the Hollywood types that often attend such affairs.\nThis change reveals the shifting economic needs of the U.K. and U.S. in the age of AI, as well as the rising prominence of technology and its leaders in Trump’s second administration. Just this past year, numerous Big Tech companies like OpenAI, Google, and Apple have pledged to work with the government, from providing AI assistant tools to government services to building digital health ecosystems for the U.S. health industry.\nThe president has also taken a sharper focus on tech — criticizing Tim Cook for Apple’s outsourced supply chain , signing an “ anti-woke ” AI order, and instructing the attorney general to investigate private companies receiving federal funds that have DEI programs deemed “illegal.”\nMark Zuckerberg, Jeff Bezos, and other tech leaders attended the president’s inauguration this year. And, in early September, President Trump threw a tech dinner with 33 top names in Silicon Valley, including Altman, Cook, and Zuckerberg. Musk, a former senior adviser to the president, once known as “ First Buddy ,” was not present at either dinner ."}
{"url": "https://techcrunch.com/2025/09/18/notion-launches-agents-for-data-analysis-and-task-automation/", "title": "Notion launches agents for data analysis and task automation", "date": "2025-09-18", "content": "At the “Make with Notion” event on Thursday, the company announced the launch of its first AI agent. The agent will draw on all of a user’s notion pages and database as context, automatically generating notes and analysis for meetings, competitor evaluation reports, and feedback landing pages.\nThe productivity platform said that the agent can create pages and databases, or update them with new data, properties, or views. Users can also trigger Notion agents from outside platforms that are linked to the service. For instance, you can ask the Notion agent to create a bug-tracking dashboard from various sources, including Slack, email, and Google Drive.\nThe newly announced Agent builds on Notion AI, a pre-existing feature that could search or summarize content. But the new agent is able to tackle more complex multistep tasks, using the powers of agentic AI. The company said that the current version of the agent can perform a task that runs up to 20 minutes across hundreds of pages.\nUsers can set up a “profile” page for the agent to instruct it to follow directions on referencing sources, style of output, and where to update tasks and final results. You’ll also be able to ask the agent to “remember” key points as people use them. Those memories will be stored on the profile page, and users can edit them there.\nIn demo videos, the company gave examples of agents that could provide feedback for landing pages and update them, create a restaurant tracker, create an analysis from meeting notes , and prepare a competition analysis report.\nAt the moment, you have to trigger these actions manually. But Notion said that the ability to create customized agents that work on a schedule or triggers is coming soon. The company will also release a template library for agents so you can pick ready-made prompts that might suit your task.\nOver the last two years, Notion has released a calendar app , a Gmail client , a meeting note-taker , and an enterprise search to get information from different sources. These are features that gave the company enough contextual building blocks to create automations. Other enterprise knowledge and productivity platforms, including Salesforce, Fireflies , and Read AI have launched their own agents to extract and update information."}
